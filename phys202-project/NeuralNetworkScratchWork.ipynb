{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'images', 'target_names', 'data', 'DESCR'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating the training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sets(n):\n",
    "    \n",
    "    \"\"\"    \n",
    "    n : int, number of terms in training set\n",
    "    \n",
    "    *****************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    training_set : dict, contains 'data' (list of arrays) and 'target' (list) where \n",
    "                   each target corresponds to a certain data of the same index.\n",
    "                   \n",
    "    test_set : dict, contains 'data' (list of arrays) and 'target' (list) where \n",
    "               each target corresponds to a certain data of the same index.\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.linspace(0,len(digits.target)-1,len(digits.target), dtype='int')   #Specialized for sklearn data set\n",
    "    np.random.shuffle(indices)                                                      #Randomize indices for random data set\n",
    "\n",
    "    training_set = {'data': [],'target': []}                                        #Creates training set dictionary\n",
    "    for i in range(n):\n",
    "        training_set['data'].append(digits.data[indices[i]])\n",
    "        training_set['target'].append(digits.target[indices[i]])\n",
    "\n",
    "    test_set = {'data': [],'target': []}                                            #Creates test set dictionary\n",
    "    for j in range(len(digits.target)-n):\n",
    "        test_set['data'].append(digits.data[indices[-(j+1)]])\n",
    "        test_set['target'].append(digits.target[indices[-(j+1)]])\n",
    "\n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 797)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set, test_set = create_sets(1000)\n",
    "len(training_set['target']), len(test_set['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mini_batch(m, training_set):\n",
    "    \n",
    "    \"\"\"\n",
    "    m : int, number of terms in mini batch\n",
    "    \n",
    "    training_set : dict, from result of create_sets\n",
    "    \n",
    "    ************************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    mini : list of dicts, \n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(training_set)\n",
    "    m_indices = np.linspace(0,n-1,n, dtype='int')                   #All indices of the training set\n",
    "    np.random.shuffle(m_indices)                                    #Randomize their order\n",
    "    \n",
    "    mini = []                                                       #Establish the 'mini' list\n",
    "    mini_in = []                                                    #List for the randomized index arrays of the mini\n",
    "    for i in range(int(n/m)):                                       #Creates ~n/m mini batches\n",
    "        mini_in.append(m_indices[i*m:(i+1)*m])                      #Mini batches of size m\n",
    "    \n",
    "    for j in range(len(mini_in)):                                                   #Translate the indices into actual data\n",
    "        mini_dat_sub = {'data': [], 'target': []}                                   #Creates intermediate dict\n",
    "        for k in range(len(mini_in[j])):\n",
    "            mini_dat_sub['data'].append(training_set['data'][mini_in[j][k]])      #Append data to intermediate dict\n",
    "            mini_dat_sub['target'].append(training_set['target'][mini_in[j][k]])  #Append target to intermediate dict\n",
    "        mini.append(mini_dat_sub)                                                   #Append dicts to 'mini' list\n",
    "        \n",
    "    return mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "m = 10\n",
    "qwe = int(n/m)\n",
    "que = n - qwe*m\n",
    "qwe,que"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Arrays\n",
    "\n",
    "These couple cells are just me fooling around with arrays and what they can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron(n,w,b):\n",
    "    \n",
    "    \"\"\"\n",
    "    n : input, array\n",
    "    \n",
    "    w : weights, array\n",
    "    \n",
    "    b : biases, array\n",
    "    \"\"\"\n",
    "    \n",
    "    out = (n*w) + b\n",
    "    return sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6147401 ,  0.0635089 ],\n",
       "       [ 0.00854868,  0.83363214]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.ones((2,2))\n",
    "w = np.random.random((2,2))*-10\n",
    "b = np.ones((2,2))*5\n",
    "perceptron(n,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fun with Gates!\n",
    "\n",
    "The following cells are excersises working with perceptrons and creating the different gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nand(x1,x2):\n",
    "    \"\"\"\n",
    "    x1, x2 : binary\n",
    "    \"\"\"\n",
    "    w_b = [np.array([-2,-2]),np.array([3])]\n",
    "    n = np.array([x1,x2])\n",
    "    out = np.sum(w_b[0]*n) + w_b[1]\n",
    "    if out > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert nand(1,1) == 0\n",
    "assert nand(1,0) == 1\n",
    "assert nand(0,1) == 1\n",
    "assert nand(0,0) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xor(x1,x2):\n",
    "    \"\"\"\n",
    "    x1, x2 : binary\n",
    "    \"\"\"\n",
    "    prime1 = nand(x1,x2)\n",
    "    prime2 = nand(x1,prime1)\n",
    "    prime3 = nand(prime1,x2)\n",
    "    out = nand(prime2,prime3)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert xor(1,1) == 0\n",
    "assert xor(1,0) == 1\n",
    "assert xor(0,1) == 1\n",
    "assert xor(0,0) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def notg(x1):\n",
    "    \"\"\"\n",
    "    x1, : binary\n",
    "    \"\"\"\n",
    "    out = nand(x1,x1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert notg(1) == 0\n",
    "assert notg(0) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def andg(x1,x2):\n",
    "    \"\"\"\n",
    "    x1, x2 : binary\n",
    "    \"\"\"\n",
    "    prime1 = nand(x1,x2)\n",
    "    out = notg(prime1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert andg(1,1) == 1\n",
    "assert andg(1,0) == 0\n",
    "assert andg(0,1) == 0\n",
    "assert andg(0,0) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def org(x1,x2):\n",
    "    \"\"\"\n",
    "    x1, x2 : binary\n",
    "    \"\"\"\n",
    "    prime1 = notg(x1)\n",
    "    prime2 = notg(x2)\n",
    "    out = nand(prime1,prime2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert org(1,1) == 1\n",
    "assert org(1,0) == 1\n",
    "assert org(0,1) == 1\n",
    "assert org(0,0) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I haven't gotten far with the actual neural network, I now have a much better idea of how to set it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Start of Neural Network Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dig = np.random.shuffle(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dig_shuffle = np.random.shuffle(digits.data)\n",
    "dig_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_setup(ni, k, npl, no):\n",
    "    \n",
    "    \"\"\"\n",
    "    ni : int, number of neurons in input layer\n",
    "    \n",
    "    k : int, number of layers (excluding input and output layer)\n",
    "    \n",
    "    npl : int, number of neurons per hidden layer\n",
    "    \n",
    "    no : int, number of neurons in output layer\n",
    "    \n",
    "    *************************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    w : list of arrays, weights between each neuron\n",
    "    \n",
    "    b : list, biases of each neuron\n",
    "    \"\"\"\n",
    "    \n",
    "#     np.random.seed(0)                           #For testing.\n",
    "    k = int(k)\n",
    "    npl = int(npl)\n",
    "    \n",
    "    w = []                                      #Weights\n",
    "    w0 = np.random.randn(ni,npl)                #First weight, all 1's\n",
    "    w.append(w0)\n",
    "    if k > 1:\n",
    "        for i in range(k-1):\n",
    "            w.append(np.random.randn(npl,npl))\n",
    "    w.append(np.random.randn(npl,no))           #Last weight, 10 outputs\n",
    "    \n",
    "    b = []                                      #Biases\n",
    "    for i in range(k):\n",
    "        b.append(np.random.randn(1,npl))\n",
    "    b.append(np.random.randn(1,no))             #Last biases, 10 outputs\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ -9.35769434e-01,   2.76550537e-02,   9.31194711e-01, ...,\n",
       "            5.68754796e-01,   5.49022708e-01,  -3.02431461e-01],\n",
       "         [  1.20731703e+00,   1.37766662e+00,   6.36283930e-01, ...,\n",
       "            1.31646817e-01,   1.10371482e+00,  -2.67684138e+00],\n",
       "         [ -2.37698464e-01,  -1.75783260e-01,  -5.58238541e-01, ...,\n",
       "           -7.77175322e-01,   9.94435002e-01,  -1.32151338e+00],\n",
       "         ..., \n",
       "         [ -5.75960961e-01,  -9.12800301e-01,   5.98687811e-03, ...,\n",
       "            3.67316770e-01,  -1.54763323e+00,   1.38630120e-03],\n",
       "         [  6.81042873e-01,   1.42840171e+00,   4.52340501e-01, ...,\n",
       "            1.05877219e+00,  -2.45661447e-01,  -4.14646956e-01],\n",
       "         [  4.04397806e-01,   7.03427772e-01,   8.88822337e-01, ...,\n",
       "           -9.73133515e-01,   1.07981279e+00,  -7.02804471e-03]]),\n",
       "  array([[  1.45810082e+00,   1.78907668e+00,  -1.33256431e+00,\n",
       "           -4.67876689e-01,  -1.02980354e-01,  -1.04640833e+00,\n",
       "           -8.16730294e-01,   1.51798683e+00,  -6.17795699e-01,\n",
       "            2.62858128e-01,  -1.90042722e+00,  -6.66032075e-01,\n",
       "           -7.93734112e-01,  -8.09270744e-01,  -1.27865198e-01,\n",
       "           -1.35454325e-01],\n",
       "         [ -1.47883394e+00,  -4.92904573e-01,   7.94947253e-01,\n",
       "           -1.09221351e+00,   2.08651464e+00,   1.31665300e+00,\n",
       "           -4.66413876e-01,  -2.13731218e+00,  -2.15491617e+00,\n",
       "           -7.50371008e-01,  -7.28036491e-01,  -9.48938824e-01,\n",
       "            1.75380092e+00,   9.75203071e-01,   9.13799721e-01,\n",
       "           -7.06304701e-01],\n",
       "         [  8.45393917e-01,  -1.43203878e-03,   1.13288535e-01,\n",
       "            4.68100725e-01,   2.84778212e+00,  -1.44020869e+00,\n",
       "           -1.69751569e-01,  -1.80531884e+00,   6.08022032e-01,\n",
       "            2.18203552e-01,   2.17547043e+00,   5.77049493e-01,\n",
       "           -1.47318056e+00,  -1.24675744e+00,   1.78606288e+00,\n",
       "           -2.30658251e+00],\n",
       "         [  9.92134261e-01,  -9.15632856e-01,  -2.43897278e-01,\n",
       "            3.48120672e-02,  -1.20670901e+00,  -7.82278609e-01,\n",
       "           -8.25585091e-02,   1.72933801e+00,   6.58276152e-01,\n",
       "           -7.93103468e-01,  -1.75502690e-02,  -8.00560637e-01,\n",
       "            1.61038533e-01,  -1.03602927e+00,  -3.40441324e-01,\n",
       "            1.77556598e+00],\n",
       "         [ -1.25453666e+00,   7.86215852e-01,  -2.78880075e-01,\n",
       "            6.93456049e-01,  -1.31956788e-01,  -4.02886049e-02,\n",
       "            3.36781159e-02,   1.40686786e+00,   1.05533584e+00,\n",
       "            2.11095650e-01,   1.44639380e+00,   1.19229395e+00,\n",
       "            1.11955157e+00,   1.23112308e+00,  -1.32317182e+00,\n",
       "            1.71518730e+00],\n",
       "         [ -1.17357315e+00,  -1.13522708e-01,   7.04551646e-01,\n",
       "           -2.08699527e+00,   7.66464556e-02,   1.06367381e+00,\n",
       "            2.30402574e-01,   8.00850913e-01,  -5.18150794e-01,\n",
       "           -1.54430876e+00,   1.09807269e-01,  -1.19519069e+00,\n",
       "           -2.89112260e-01,  -8.64508669e-01,   2.27022467e-01,\n",
       "           -8.24001347e-01],\n",
       "         [ -4.30445962e-01,   2.28141293e+00,  -8.20571864e-03,\n",
       "           -1.91369574e-01,   1.26051568e+00,   4.98894509e-01,\n",
       "            1.41000386e+00,   4.15301055e-01,   3.91957736e-01,\n",
       "           -2.22396504e-01,   1.43540371e+00,   3.34722119e-01,\n",
       "            1.87636562e-02,   2.10073305e+00,  -2.07478977e+00,\n",
       "           -6.26460014e-01],\n",
       "         [  8.55082322e-01,  -8.14339310e-01,  -6.92897131e-01,\n",
       "            6.15313586e-01,   6.98009600e-02,   7.14195477e-01,\n",
       "           -6.21046642e-01,   6.63072485e-03,  -5.00597469e-01,\n",
       "           -9.92777287e-01,  -9.86820810e-01,   7.59064298e-01,\n",
       "           -2.31260197e+00,  -3.23173526e-01,  -1.07391178e+00,\n",
       "            3.09866328e-01],\n",
       "         [ -3.10434792e-01,   6.35883050e-01,   4.27389756e-01,\n",
       "           -1.81292069e+00,   5.20387172e-01,  -3.91445894e-01,\n",
       "            1.23556360e-02,  -2.86327565e-01,   4.89334162e-01,\n",
       "            2.27565779e+00,  -1.10541966e-01,   2.25477708e+00,\n",
       "           -6.11964328e-01,  -3.30991249e-01,   1.24196358e+00,\n",
       "            1.62109864e-01],\n",
       "         [  7.10566436e-01,   3.67004222e-01,   1.66673009e+00,\n",
       "           -1.36326501e+00,  -9.82132713e-01,   4.08619769e-01,\n",
       "            2.77705299e+00,  -6.14567781e-01,   5.54050439e-01,\n",
       "            1.86902158e+00,   9.90264018e-01,   2.30156111e+00,\n",
       "           -1.59314752e+00,  -1.10628412e+00,  -1.99538477e+00,\n",
       "           -5.20461887e-01],\n",
       "         [  2.72640840e-01,  -8.41445099e-01,   3.00688728e-01,\n",
       "            2.96138111e-01,  -7.07438941e-01,   5.00652338e-01,\n",
       "           -6.29601800e-01,  -8.20655788e-01,   1.09399281e+00,\n",
       "            1.91047475e+00,   9.32785078e-01,  -5.31507616e-01,\n",
       "            5.54529766e-01,   9.72545970e-01,   5.30842807e-01,\n",
       "           -1.94930557e-01],\n",
       "         [ -2.64768063e+00,   7.17493611e-01,   2.32715330e-02,\n",
       "            9.78933837e-02,  -6.13398907e-01,  -2.15084508e+00,\n",
       "           -1.41027003e-01,   1.13590104e+00,   7.16332288e-01,\n",
       "           -5.74505153e-01,   5.02101740e-02,  -3.73555497e-01,\n",
       "           -2.01397829e+00,   1.68239443e-01,   1.48346341e+00,\n",
       "            1.90611926e+00],\n",
       "         [ -2.17367227e-01,   5.84377686e-01,  -1.83784677e+00,\n",
       "           -1.19830474e+00,   4.02655191e-01,   4.84106124e-01,\n",
       "           -1.53384352e+00,  -8.74171152e-01,  -7.96323827e-01,\n",
       "            7.43140158e-01,  -2.59042076e-01,   4.17884113e-02,\n",
       "            1.09924163e+00,   5.34623055e-01,  -1.01008856e+00,\n",
       "            6.72298818e-02],\n",
       "         [ -1.07617688e+00,   1.26054492e-01,   1.17513889e+00,\n",
       "            8.67448889e-01,   6.99060490e-01,   4.74507419e-01,\n",
       "            9.59074975e-01,   2.82233724e-01,   7.59553930e-01,\n",
       "            1.54724904e-01,   5.32075316e-01,   2.54969952e-01,\n",
       "            9.92710788e-01,   1.06991674e+00,  -5.31279790e-01,\n",
       "           -1.03330964e+00],\n",
       "         [ -1.87094721e-01,   1.89601571e+00,   6.80776424e-01,\n",
       "           -2.31574729e+00,   7.33671536e-01,  -9.46280829e-01,\n",
       "            9.81719174e-02,  -1.52506060e+00,  -2.34513104e+00,\n",
       "            1.70054985e+00,   1.00426999e+00,   1.56557679e+00,\n",
       "            6.15284978e-01,  -1.46456753e+00,   2.08249262e+00,\n",
       "           -2.80156222e+00],\n",
       "         [ -1.28697185e-01,  -6.53836298e-01,  -6.93869008e-01,\n",
       "           -2.28739530e+00,  -1.46686111e+00,  -4.02087573e-01,\n",
       "            1.41893132e+00,  -9.46419301e-01,   4.91311802e-01,\n",
       "            5.36785136e-01,   9.38207598e-01,  -5.81286543e-01,\n",
       "            1.19575602e+00,  -1.13297396e+00,   6.50963512e-01,\n",
       "           -7.11720358e-01]]),\n",
       "  array([[ -7.71000125e-01,  -5.99212522e-01,  -1.54017513e+00,\n",
       "           -9.44260641e-01,   3.42426154e-01,   6.81438920e-01,\n",
       "           -1.24991750e-01,   1.01572972e+00,  -1.52814392e+00,\n",
       "           -6.61025056e-02],\n",
       "         [  7.31564937e-01,   8.42538624e-01,   8.03017812e-04,\n",
       "            2.24287466e+00,   2.18727343e-01,  -1.14232329e+00,\n",
       "            2.97722651e-01,  -1.50098898e+00,   1.02454951e+00,\n",
       "           -3.22026530e-01],\n",
       "         [ -4.17242873e-01,   2.83283486e-01,  -1.16927124e-01,\n",
       "           -2.02030661e+00,  -2.24102266e+00,  -3.28702658e-01,\n",
       "            2.16680065e-01,   5.48388081e-01,  -2.69218103e-01,\n",
       "           -8.39024318e-01],\n",
       "         [  1.06349723e-01,  -8.50801749e-01,   2.09558326e-02,\n",
       "           -1.53532355e+00,  -3.31030869e-01,  -1.90040163e+00,\n",
       "            1.85956421e+00,  -4.67458752e-01,   9.65317711e-01,\n",
       "           -4.69674994e-01],\n",
       "         [ -3.34818067e-02,   1.06215723e-01,  -8.03833864e-01,\n",
       "           -4.72195530e-01,  -3.88249797e-01,   6.22519514e-01,\n",
       "           -7.74414102e-01,   3.63965545e-01,   6.52260476e-01,\n",
       "           -7.29590437e-01],\n",
       "         [  9.57832012e-02,   5.94511992e-01,   5.47795120e-01,\n",
       "            3.15049178e-01,   1.58856217e+00,  -9.62152603e-01,\n",
       "            1.99920556e+00,  -9.98908523e-01,  -6.56690595e-01,\n",
       "            6.36490718e-01],\n",
       "         [  2.25837755e+00,  -9.02690685e-01,  -1.51556739e+00,\n",
       "            2.13737818e-02,  -5.02794361e-01,   1.98276364e+00,\n",
       "            3.94150983e-01,  -6.98127656e-01,   8.33506626e-01,\n",
       "            7.11611678e-01],\n",
       "         [ -1.51715126e+00,   2.81908709e+00,   5.60013428e-01,\n",
       "           -1.84587301e-02,  -1.27852345e-01,   1.91798559e+00,\n",
       "            3.39359549e-01,   2.32295391e-01,  -1.80383089e+00,\n",
       "           -6.36902735e-01],\n",
       "         [ -1.67274417e+00,   2.08856788e-01,   5.33291990e-01,\n",
       "           -3.25303423e+00,  -1.30797466e-01,  -1.76031591e+00,\n",
       "            4.97777802e-01,   4.10435319e-01,  -1.12497024e+00,\n",
       "            1.00147452e-02],\n",
       "         [  3.01589102e-01,   2.34380099e-01,   2.05200515e+00,\n",
       "            3.50756701e-01,  -1.33699760e+00,   6.33441829e-02,\n",
       "            1.50729552e-01,  -7.02793872e-02,  -2.42681041e-01,\n",
       "            9.83634844e-01],\n",
       "         [  1.96344410e+00,   1.49944712e+00,  -6.94323980e-01,\n",
       "           -6.50843200e-01,   6.47849799e-01,   3.00088222e-01,\n",
       "            2.08847698e+00,   5.63321655e-01,  -8.29616484e-01,\n",
       "           -1.46715272e+00],\n",
       "         [  2.08221912e-01,   1.75099507e+00,  -7.93716302e-01,\n",
       "            1.72081971e-02,   1.75415486e-01,  -6.22033284e-01,\n",
       "            1.07912923e+00,   1.26385501e+00,   4.36130935e-02,\n",
       "           -1.86225954e+00],\n",
       "         [ -4.80382486e-01,  -5.94831172e-02,   8.75781410e-02,\n",
       "           -2.44460224e-02,   1.21229949e-01,  -7.16319085e-01,\n",
       "           -3.74067778e-02,   7.80678210e-01,  -6.56597122e-01,\n",
       "            6.07064761e-01],\n",
       "         [  5.57284119e-01,   9.97611508e-01,  -2.96551703e-01,\n",
       "           -1.87991624e+00,   4.64719972e-01,   1.69461834e+00,\n",
       "            1.57588635e+00,   9.55906846e-01,   1.73205086e+00,\n",
       "           -3.24548812e-01],\n",
       "         [  9.47864656e-01,  -6.03646023e-01,  -4.76838784e-01,\n",
       "            4.61682436e-01,  -3.17318725e-01,  -9.02049852e-01,\n",
       "            8.14128389e-01,   2.15341434e-01,   1.43031520e+00,\n",
       "           -1.32360011e+00],\n",
       "         [ -4.20719815e-01,  -5.17254450e-01,  -2.32677284e-01,\n",
       "            7.21345700e-01,  -1.15926345e+00,   1.07083317e+00,\n",
       "           -4.98975553e-01,   1.15825139e+00,   1.50105535e+00,\n",
       "            1.84296179e+00]])],\n",
       " [array([[-1.01325919, -0.37642767,  0.74762153,  0.94363377, -0.42556171,\n",
       "           0.80577795,  0.05685318, -0.55135829, -0.60418842,  1.23496869,\n",
       "          -0.10311052, -0.36885447,  1.89256941,  0.18734924, -1.23435415,\n",
       "           0.10513428]]),\n",
       "  array([[-0.22183946, -0.33988959,  0.30965711, -2.26531123,  0.23496376,\n",
       "          -0.99721028,  0.53044694,  0.57039884, -2.68512486,  0.4895471 ,\n",
       "           0.64186014,  0.23303756, -0.76063175,  1.24365175,  0.85027109,\n",
       "          -0.9541359 ]]),\n",
       "  array([[ 0.13331125,  1.39589955,  1.14883261,  1.08959712, -0.14069045,\n",
       "           1.18391882,  1.55520159,  2.04898474,  0.68593475,  0.44069264]])])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt,bt = network_setup(64, 2, 16, 10)\n",
    "wt,bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_test, b_test = network_setup(100,3,25,3)\n",
    "assert len(w_test) == 4\n",
    "assert len(b_test) == 4\n",
    "assert w_test[0].shape == (100, 25)\n",
    "assert w_test[1].shape == w_test[2].shape == (25,25)\n",
    "assert w_test[3].shape == (25,3)\n",
    "assert b_test[0].shape == b_test[1].shape == b_test[2].shape == (1,25)\n",
    "assert b_test[3].shape == (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feedforward(w,b,x):\n",
    "    \n",
    "    \"\"\"\n",
    "    w, b : weights and biases from network_setup\n",
    "    \n",
    "    x : input neuron values\n",
    "    \n",
    "    **************************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    z : array of activation function inputs\n",
    "    \n",
    "    a : array of activation function outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    z = []                                                  #Array of activation function inputs\n",
    "    a = []                                                  #Initialize array for activation function values\n",
    "    a.append(x)\n",
    "    for i in range(k+1):                                    #k+1 involves hidden layers plus output layer\n",
    "        zi = []\n",
    "        for j in range(len(b[i][0,:])):\n",
    "            zi.append(np.sum(w[i][:,j]*a[i]) + b[i][0,j])   #Loop through each weight and bias array to get z values of all neurons in the next layer.\n",
    "        zz = np.array(zi)\n",
    "        z.append(zz)\n",
    "        a.append(sigmoid(zz))                               #Array of outputs\n",
    "    return z, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "ni = 4\n",
    "k = 1\n",
    "npl = 3\n",
    "no = 2\n",
    "wff,bff = network_setup(ni,k,npl,no)\n",
    "x = np.random.randn(ni)\n",
    "zff,aff = feedforward(wff,bff,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost(n, y, a):\n",
    "    \n",
    "    \"\"\"\n",
    "    n : int, total number of training examples\n",
    "    \n",
    "    y : array, desired output\n",
    "    \n",
    "    a : list of arrays, output from activation functions\n",
    "    \n",
    "    ***********************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    c : float, cost function value\n",
    "    \"\"\"\n",
    "    \n",
    "    return (1/(2*n))*np.sum((y-a)**2)               # Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    return np.exp(-x)/((1+np.exp(-x))**2)           # First derivative of sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def act_error(a, y, z, w):\n",
    "    \n",
    "    \"\"\"\n",
    "    a : output from network\n",
    "    \n",
    "    y : desired output\n",
    "    \n",
    "    z : weighted input array\n",
    "    \n",
    "    w : weights list of arrays\n",
    "    \n",
    "    **********************************\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    delta : list of arrays, error from each from neuron\n",
    "    \"\"\"\n",
    "    \n",
    "    delta = []                                      #Sets up delta list\n",
    "    y_con = np.zeros(10)\n",
    "    y_con[y] = 1                                    #Converts a digit 0-9 into the network output format\n",
    "    \n",
    "    d = (a - y_con)*sigmoid_prime(z[-1])                                        #Calculate error for last neuron layer\n",
    "    delta.append(d)                                                             #Append it to delta list\n",
    "    for i in range(k):                                                          #Cycle through each other layer...\n",
    "        di = delta[0]*np.transpose(w[-(i+1)])*sigmoid_prime(z[-(i+2)])          #...in reverse order\n",
    "        delta.insert(0,di)\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace(w,b,eta,m,delta,a):\n",
    "    for i in range(len(w)):\n",
    "        w[-(i+1)] = w[-(i+1)] - (eta/m)*np.sum(delta[-(i+1)]*a[-(i+2)])\n",
    "        b[-(i+1)] = b[-(i+1)] - (eta/m)*np.sum(delta[-(i+1)])\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_net(w,b,test_set,k):\n",
    "    count = 0\n",
    "    for i in range(len(test_set['target'])):\n",
    "        x = test_set['data'][i]\n",
    "        y = test_set['target'][i]\n",
    "        y_con = np.zeros(10)\n",
    "        y_con[y] = 1\n",
    "        z, a = nn.feedforward(w,b,x,k)\n",
    "        out = a[-1]\n",
    "        for j in range(len(out)):\n",
    "            if out[j] > 0.5:\n",
    "                out[j] = 1\n",
    "            else:\n",
    "                out[j] = 0\n",
    "        if out == y_con:\n",
    "            count += 1\n",
    "    print('Accuracy: {0}/{1}'.format(count,len(test_set['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
